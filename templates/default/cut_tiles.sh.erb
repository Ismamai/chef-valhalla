#!/bin/bash
set -e

function mv_stamp() {
  local b=$(basename ${1})
  mv ${1} ${b%.*}_${2}.${b##*.}
}

function cp_stamp() {
  local b=$(basename ${1})
  cp -rp ${1} ${b%.*}_${2}.${b##*.}
}

function clean_s3() {
  cutoff=$(date -d "-${2} days" +%s)
  aws s3 ls ${1} | tail -n +2 | while read record; do
    added=$(date -d "$(echo ${record} | awk '{print $1" "$2}')" +%s)
    if [[ ${added} -lt ${cutoff} ]]; then
      aws s3 rm ${1}$(echo ${record} | awk '{print $4}')
    fi
  done
}

# make sure only one is running at any time...
LOCK_FILE="<%= node[:valhalla][:lock_dir] %>/cut_tiles.lock"
(set -C; : > ${LOCK_FILE}) 2> /dev/null
if [ $? != "0" ]; then
  echo "Lock file exists"
  exit 0
fi
trap 'rm $LOCK_FILE' EXIT 1 2 3

export PATH=$PATH:/usr/sbin:/usr/local/bin
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/lib

# name the dir where this will go
stamp=$(date +%Y_%m_%d-%H_%M_%S)

# things we need to make if we dont have them
extracts=$(find <%= node[:valhalla][:extracts_dir] %> -type f -name "*.pbf")
admin_file=$(jq -r '.mjolnir.admin' <%= node[:valhalla][:config] %>)
timezone_file=$(jq -r '.mjolnir.timezone' <%= node[:valhalla][:config] %>)
if [ ! -e $admin_file ]; then
  valhalla_build_admins -c <%= node[:valhalla][:config] %> $(find <%= node[:valhalla][:extracts_dir] %> -type f -name "*.pbf")
fi
if [ ! -e $timezone_file ]; then
  valhalla_build_timezones <%= node[:valhalla][:config] %>
fi

#transit data
if [ -f <%= node[:valhalla][:transit_dir] %>.tgz ]; then
  rm -rf <%= node[:valhalla][:transit_dir] %>
  mkdir <%= node[:valhalla][:transit_dir] %>
  tar pxf <%= node[:valhalla][:transit_dir] %>.tgz -C <%= node[:valhalla][:transit_dir] %>
fi

# cut tiles from the data
valhalla_build_tiles -c <%= node[:valhalla][:config] %> $(find <%= node[:valhalla][:extracts_dir] %> -type f -name "*.pbf")
rm -rf *.bin

# see if these tiles are any good
<%= node[:valhalla][:test_dir] %>/test_tiles.sh

# package up the extra stuff
set +e
tile_dir=<%= node[:valhalla][:tile_dir] %>
cur_extras_dir=<%= node[:valhalla][:base_dir] %>/extras_${stamp}
mkdir -p ${cur_extras_dir}
pushd ${cur_extras_dir}
valhalla_build_connectivity -c <%= node[:valhalla][:config] %>
valhalla_build_statistics -c <%= node[:valhalla][:config] %>
valhalla_export_edges --config <%= node[:valhalla][:config] %> > edges_${stamp}.0sv
# do we want to run map roulette tool
if [ "<%= node[:valhalla][:with_map_roulette] %>" == true ]; then
  <%= node[:valhalla][:conf_dir] %>/map_roulette.py -c <%= node[:maproulette][:config] %> -i maproulette_tasks.geojson
fi
for f in connectivity*; do  mv_stamp $f ${stamp}; done
mv_stamp statistics.sqlite ${stamp}
mv_stamp maproulette_tasks.geojson ${stamp}
cp_stamp <%= node[:valhalla][:transit_dir] %>.tgz ${stamp}
cp_stamp ${tile_dir}/$(basename ${admin_file}) ${stamp}
cp_stamp ${tile_dir}/$(basename ${timezone_file}) ${stamp}
find ${tile_dir}/* | sort -n | tar cf planet_${stamp}.tar --no-recursion -T -
popd

# do we want to send this update to s3 (do so in the background)
if [ "<%= node[:valhalla][:with_updates] %>" == true ]; then
  {
    #clean up s3 old files
    clean_s3 s3://<%= node[:valhalla][:bucket] %>/<%= node[:valhalla][:bucket_dir] %>/ 30
    #push up s3 new files
    for f in ${cur_extras_dir}/*; do
      aws s3 mv ${f} s3://<%= node[:valhalla][:bucket] %>/<%= node[:valhalla][:bucket_dir] %>/ --acl public-read
    done
    #signal other stacks to get new data
    aws s3 ls s3://<%= node[:valhalla][:bucket] %>/<%= node[:valhalla][:bucket_dir] %>/planet_${stamp}.tar
    if [[ $? -eq 0 ]]; then
      <%= node[:valhalla][:conf_dir] %>/push_tiles.py
    fi
    #clean it up the new stuff
    rm -rf ${cur_extras_dir}
  }&
fi
