#!/usr/bin/env python
from __future__ import print_function
import sys
import os
import stat
import math
import time
import boto
from filechunkio import FileChunkIO

#do some maintainance on s3, including pushing the new data up there
def push_to_s3(file_name, bucket_name = '<%= node[:valhalla][:bucket] %>'):
  #check what we have in s3
  s3 = boto.connect_s3()
  bucket = s3.get_bucket(bucket_name)

  #get ready for multi part
  source_size = os.stat(file_name).st_size
  multipart = bucket.initiate_multipart_upload(file_name)
  chunk_size = 536870912
  chunk_count = int(math.ceil(float(source_size) / float(chunk_size)))

  #send them
  print('Pushing %s to s3' % file_name)
  for i in range(chunk_count):
    offset = chunk_size * i
    bytes = min(chunk_size, source_size - offset)
    with FileChunkIO(file_name, 'r', offset=offset, bytes=bytes) as fp:
      multipart.upload_part_from_file(fp, part_num=i + 1)
      print('Part pushed to s3 %%%f' % (100 * float(offset + bytes) / float(source_size)))
  multipart.complete_upload()

  #check its ok and make it public
  key = bucket.get_key(file_name)
  if key is None:
    raise Exception('Failed to push file to s3')
  key.make_public()

#entry point for script
if __name__ == "__main__":
  if len(sys.argv) < 3:
    print('Wrong arguments', file=sys.stderr)
    sys.exit(1)

  #check all the files are there
  try:
    for dir,subdirs,files in os.walk(sys.argv[1]):
      for file in files:
        push_to_s3(os.path.join(dir, file), '<%= node[:valhalla][:bucket] %>')
  except:
    print('%s is not a directory' % sys.argv[1])
